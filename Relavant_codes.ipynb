{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use PySpark SQL\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as fn\n",
    "\n",
    "#other modules\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "#Saving/reading data to/from disk\n",
    "import dill\n",
    "#python dataframe module\n",
    "import pandas as pd\n",
    "#Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "#Geo-data plotting\n",
    "import geojson\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up Spark\n",
    "#Create a SparkContext\n",
    "#sc.stop()\n",
    "sc = SparkContext(\"local[*]\", \"pyspark_df\")\n",
    "\n",
    "#Create a SQLContext\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def localpath(path):\n",
    "    return 'file://' + os.path.join(os.path.abspath(os.path.curdir), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for part 1 starts here. \n",
    "I read the records and count the number of prescriptions per month for each practice. After that the data were binned and a k-means clustering was performed to group and label the practices. When I have grouped the practices by how many HCPs each one has, the data was plotted with respect to each practice's geolocation and compared to a few geolocation related factors that are publically available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read 18-month records during 201702-201807 using Spark\n",
    "df_grouped = []\n",
    "for n in [201702,201703,201704,201705,201706,201707,201708,201709,201710,201711,201712,201801,201802,201803,201804,201805,201806,201807]:\n",
    "    records = sc.textFile(localpath('data/PDPI/'+str(n)+'/'))\n",
    "    df_rec = records.map(lambda line: line.split(','))\\\n",
    "                    .filter(lambda u: u[1] != 'PCT')\\\n",
    "                    .map(lambda u: (u[2],float(u[6]),int(u[9]))).toDF()\n",
    "    df_rec = df_rec.withColumnRenamed(\"_1\", \"Practice_Code\")\\\n",
    "                   .withColumnRenamed(\"_2\", \"NIC\")\\\n",
    "                   .withColumnRenamed(\"_3\", \"Date\")\n",
    "    #print(df_rec.head())\n",
    "    if df_grouped == []:\n",
    "        df_grouped = df_rec.groupBy(['Practice_Code','Date'])\\\n",
    "                           .agg(fn.count('NIC').alias('Count'),fn.sum('NIC').alias('NIC_sum'))\n",
    "    else:\n",
    "        df_grouped = df_grouped.union(\\\n",
    "                                      df_rec.groupBy(['Practice_Code','Date'])\\\n",
    "                                     .agg(fn.count('NIC').alias('Count'),fn.sum('NIC').alias('NIC_sum'))\\\n",
    "                                     )\n",
    "\n",
    "#dill is an advanced version of pickle. Allows easy writing/reading data to/from disk.\n",
    "#Except for gathering info from the records, all dataframe manipulations were done using Pandas\n",
    "dill.dump(df_grouped.toPandas(), open('grouped_records_cost.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out the dummy practices\n",
    "df_grouped = dill.load(open('grouped_records_cost.pkd', 'rb'))\n",
    "df_grouped.loc[df_grouped['Practice_Code'].apply(lambda s: 'Y' not in s)]\n",
    "dill.dump(df_grouped,open('grouped_records_cost.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the statistics with a GroupBy.\n",
    "df_grouped = dill.load(open('grouped_records_cost.pkd', 'rb'))\n",
    "df_stats_all = df_grouped.groupby('Practice_Code')['Count','NIC_sum']\\\n",
    "                .agg([np.median,np.var]).dropna()\n",
    "#Rename the columns\n",
    "df_stats_all.columns = [' '.join(col).strip() for col in df_stats_all.columns.values]\n",
    "#df_stats_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram the data and plot using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df_stats_all['NIC_sum median'].tolist()\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.hist(np.asarray(median),bins=np.arange(50)*3e5/50)\n",
    "#ax.set_ylim((0,500))\n",
    "ax.set_xlabel('Sum(NIC) per month \\n (median in 18 months)')\n",
    "ax.set_ylabel('Number of practices')\n",
    "fig.tight_layout()\n",
    "fig.savefig('hist1_1.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df_stats_all['Count median'].tolist()\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.hist(np.asarray(median),bins=np.arange(50)*50)\n",
    "#ax.set_ylim((0,500))\n",
    "ax.set_xlabel('#Prescriptions per month \\n (median in 18 months)')\n",
    "ax.set_ylabel('Number of practices')\n",
    "fig.tight_layout()\n",
    "fig.savefig('hist1.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how long a practice has been around and group the data accordingly. Make histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practices = sc.textFile(localpath('data/ADDR/'))\n",
    "\n",
    "df_prac_age = practices.map(lambda line: line.split(','))\\\n",
    "              .map(lambda u: (u[0].strip(),u[1].strip()))\\\n",
    "              .filter(lambda v: 'Y' not in v[1])\\\n",
    "              .toDF()\\\n",
    "              .withColumnRenamed('_1','Date').withColumnRenamed('_2','Practice_Code')\n",
    "df_prac_age = df_prac_age.groupBy('Practice_Code').count()\\\n",
    "                           .withColumnRenamed('count','Months')\n",
    "\n",
    "dill.dump(df_prac_age.toPandas(), open('df_prac_age.pkd', 'wb'))\n",
    "\n",
    "y = [row.Months for row in df_prac_age.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.hist(np.asarray(y),bins=np.arange(20)*5)\n",
    "ax.set_xlabel('Number of months on record since 2011/08')\n",
    "ax.set_ylabel('Number of practices')\n",
    "fig.tight_layout()\n",
    "fig.savefig('hist1_2.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the data by how long the practice has been around\n",
    "df_prac_age = dill.load(open('df_prac_age.pkd', 'rb'))\n",
    "\n",
    "df = df_stats_all.join(df_prac_age.set_index('Practice_Code'))\n",
    "group1 = df.loc[df['Months'] > 80]\n",
    "group2 = df.loc[df['Months'] <= 80]\n",
    "\n",
    "median1 = group1['NIC_sum median'].tolist()\n",
    "median2 = group2['NIC_sum median'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.hist(np.asarray(median1),bins=np.arange(50)*3e5/50,alpha=0.5,label='> 80 months')\n",
    "ax.hist(np.asarray(median2),bins=np.arange(50)*3e5/50,alpha=0.5,label='<= 80 months')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Sum(NIC) per month \\n (median during 2017/02-2018/07)')\n",
    "ax.set_ylabel('Number of practices')\n",
    "ax.set_title('Group the data by \\n how many months the practice has on record')\n",
    "fig.tight_layout()\n",
    "fig.savefig('hist1_3.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot a sample of the data with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_ngp = pd.read_csv('df_sample_ngp.csv').dropna()\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "for i in range(1,5):\n",
    "    df = df_sample_ngp.loc[df_sample_ngp['nGP']==i]\n",
    "    s = 'nGP = '+str(i)\n",
    "    median = np.asarray(df['Count median'].tolist())\n",
    "    var = np.asarray(df['Count var'].tolist())\n",
    "    ax.plot(median,var,'o',label=s)\n",
    "df = df_sample_ngp.loc[df_sample_ngp['nGP']>=5.]\n",
    "s = 'nGP >= 5'\n",
    "median = np.asarray(df['Count median'].tolist())\n",
    "var = np.asarray(df['Count var'].tolist())\n",
    "ax.plot(median,var,'o',label=s)\n",
    "\n",
    "#ax.set_xlim((300,1900))\n",
    "ax.legend()\n",
    "ax.set_xlabel('Median #prescriptions')\n",
    "ax.set_ylabel('Var #prescriptions')\n",
    "fig.savefig('scatter1.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means. Filter the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure all entry has 12-month worth of data\n",
    "df_prac_age = dill.load(open('df_prac_age.pkd', 'rb'))\n",
    "\n",
    "filter2 = pd.DataFrame()\n",
    "filter2['Months'] = df_grouped.groupby('Practice_Code')['Date'].count()\n",
    "filter2 = filter2.loc[filter2.Months ==18]\n",
    "\n",
    "#Join all filters\n",
    "df = df_stats_all.join(filter2,how='inner')\n",
    "df = df.drop(columns=['Months'])\n",
    "filtered_data = df.join(df_prac_age.set_index('Practice_Code'),how='inner').drop(columns=['Months'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform clustering analysis using scikit-learn's k-means class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Somewhat arbitary cut\n",
    "sample = filtered_data.loc[filtered_data['Count median'] >300]\n",
    "sample = sample.loc[sample['Count var'] < 6000].sort_values('Count var')\n",
    "y = sample['Count var'].tolist()\n",
    "\n",
    "estimator = KMeans(n_clusters=5).fit(np.asarray(y).reshape(-1, 1))\n",
    "print(estimator.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels generated are not ordered, so relabel them. Plot the histograms with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = sample.index\n",
    "dict_label = {}\n",
    "for i in range(len(keys)):\n",
    "    dict_label[keys[i]] = int(estimator.labels_[i])\n",
    "\n",
    "df_labels = pd.DataFrame.from_dict(dict_label,orient='index',columns=['Label'])\n",
    "kmeans = sample.join(df_labels)\n",
    "\n",
    "#A dictionary for which kmeans label correspond to how many GPs\n",
    "dict_kcenter = {0:2,1:4,2:1,3:5,4:3}\n",
    "kmeans['nGP'] = kmeans['Label'].apply(lambda n: dict_kcenter[n])\n",
    "\n",
    "dill.dump(kmeans, open('df_kmeans.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "for i in range(5):\n",
    "    ki = kmeans.loc[kmeans['nGP'] == i+1]\n",
    "    var = ki['Count var'].tolist()\n",
    "    s = '#HCP = '+str(i+1)\n",
    "    if i+1 == 5:\n",
    "        s = s+' or more'\n",
    "    ax.hist(np.asarray(var),bins=np.arange(60)*100,stacked=True,alpha=0.5,label=s)\n",
    "ax.legend()\n",
    "ax.set_xlabel('Variation of #prescriptions per month \\n (during 2017/02-2018/07)')\n",
    "ax.set_ylabel('Number of practices')\n",
    "ax.set_title('Group by how many HCPs the practice has')\n",
    "fig.tight_layout()\n",
    "fig.savefig('hist1_4.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "for i in range(5):\n",
    "    ki = kmeans.loc[kmeans['nGP'] == i+1]\n",
    "    median = ki['NIC_sum median'].tolist()\n",
    "    s = '#HCP = '+str(i+1)\n",
    "    if i+1 == 5:\n",
    "        s = s+' or more'\n",
    "    ax.hist(np.asarray(median),bins=np.arange(50)*3e5/50,stacked=True,alpha=0.5,label=s)\n",
    "ax.legend()\n",
    "ax.set_xlabel('Median of sum(NIC) per month \\n (during 2017/02-2018/07)')\n",
    "ax.set_ylabel('Number of practices')\n",
    "ax.set_title('Group by how many HCPs the practice has')\n",
    "fig.tight_layout()\n",
    "fig.savefig('hist1_5.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "for i in range(4):\n",
    "    ki = kmeans.loc[kmeans['nGP'] == i+1]\n",
    "    median = ki['NIC_sum median'].tolist()\n",
    "    s = '#HCP = '+str(i+1)\n",
    "    if i+1 == 5:\n",
    "        s = s+' or more'\n",
    "    ax.hist(np.asarray(median)/(i+1),bins=np.arange(50)*2.e5/50,stacked=True,alpha=0.5,label=s)\n",
    "ax.legend()\n",
    "ax.set_xlabel('Normalized sum(NIC) per month \\n (during 2017/02-2018/07)')\n",
    "ax.set_ylabel('Number of practices')\n",
    "ax.set_title('Group by how many HCPs the practice has')\n",
    "fig.tight_layout()\n",
    "fig.savefig('hist1_5.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "for i in range(4):\n",
    "    ki = kmeans.loc[kmeans['nGP'] == i+1]\n",
    "    median = ki['Count median'].tolist()\n",
    "    s = '#HCP = '+str(i+1)\n",
    "    if i+1 == 5:\n",
    "        s = s+' or more'\n",
    "    ax.hist(np.asarray(median)/(i+1),bins=np.arange(50)*50,stacked=True,alpha=0.5,label=s)\n",
    "ax.legend()\n",
    "ax.set_xlabel('Normalized #prescriptions per month \\n (during 2017/02-2018/07)')\n",
    "ax.set_ylabel('Number of practices')\n",
    "ax.set_title('Group by how many HCPs the practice has')\n",
    "fig.tight_layout()\n",
    "fig.savefig('hist5.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work on the geo-location data. Plot the data to postcode areas using folium. The generated html files are interactive maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read address book of csv's and generate a table for geolocation of practices\n",
    "#I decided to use the Postcode areas for cleaner information\n",
    "\n",
    "def find_areacode(string):\n",
    "    s = ''\n",
    "    for x in string:\n",
    "        if x.isalpha():\n",
    "            s = s+x\n",
    "        else:\n",
    "            break\n",
    "    return s\n",
    "\n",
    "#Create an RDD for the addr files\n",
    "practices = sc.textFile(localpath('data/ADDR/'))\n",
    "\n",
    "#Read lines, extract data and convert to Spark SQL dataframe\n",
    "df_geo = practices.map(lambda line: line.split(','))\\\n",
    "              .map(lambda u: (int(u[0]),u[1].strip(),find_areacode(u[7])))\\\n",
    "              .distinct().toDF()\n",
    "df_geo = df_geo.withColumnRenamed(\"_1\", \"Date\")\\\n",
    "               .withColumnRenamed(\"_2\", \"Practice_Code\").withColumnRenamed(\"_3\", \"Postcode_Area\")\n",
    "\n",
    "#In case of a practice with more than one location, keep the latest one.\n",
    "lastentry_udf_str = udf(lambda u: u[-1], StringType())#Define the udf\n",
    "df_geo = df_geo.orderBy(['Date','Practice_Code'])\\\n",
    "               .groupBy('Practice_Code').agg(fn.collect_list('Postcode_Area').alias('list'))\n",
    "df_geo = df_geo.withColumn('Postcode_Area',lastentry_udf_str(df_geo.list))\\\n",
    "               .select('Practice_Code','Postcode_Area')\n",
    "\n",
    "#Save to disk\n",
    "dill.dump(df_geo.toPandas(), open('df_geo.pkd', 'wb'))\n",
    "#df_geo = dill.load(open('df_geo.pkd', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = dill.load(open('df_kmeans.pkd', 'rb'))\n",
    "kmeans['Normalized NIC sum'] = kmeans['NIC_sum median']/kmeans['nGP']\n",
    "kmeans['Normalized count'] = kmeans['Count median']//kmeans['nGP']\n",
    "df_geo = dill.load(open('df_geo.pkd', 'rb'))\n",
    "kmeans_geo = kmeans.join(df_geo.set_index('Practice_Code'))\n",
    "\n",
    "kn = []\n",
    "for i in range(4):\n",
    "    ki = kmeans_geo.loc[kmeans_geo['nGP']==i+1]\n",
    "    ki = ki.groupby('Postcode_Area')['NIC_sum median'].agg([np.median,'count'])\n",
    "    kn.append(ki)\n",
    "\n",
    "#Read population data from csv\n",
    "df_pop = pd.read_csv(os.path.join(os.path.abspath(os.path.curdir), 'pop_density.csv'))\n",
    "def select_area(s):\n",
    "    return s.partition('-')[0].strip()\n",
    "df_pop['Postcode_Area'] = df_pop['postcode areas'].apply(select_area)\n",
    "df_pop = df_pop.drop(columns='postcode areas')\n",
    "\n",
    "#Read postcode area topology data\n",
    "post_area = os.path.join(os.path.abspath(os.path.curdir), 'Areas.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = pd.read_csv(os.path.join(os.path.abspath(os.path.curdir), '419412172.csv'))\n",
    "#df_age.head()\n",
    "df_age['Postcode_Area'] = df_age['mnemonic'].apply(select_area)\n",
    "df_age = df_age.drop(columns=['postcode areas','mnemonic'])\n",
    "df_age['Over 60'] = df_age['Age 60 to 64']+df_age['Age 65 to 74']\\\n",
    "                    +df_age['Age 75 to 84']+df_age['Age 85 to 89']+df_age['Age 90 and over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = kn[0].join(df_pop.set_index('Postcode_Area'))\n",
    "df['Postcode_Area'] = df.index\n",
    "\n",
    "#Create a folium map instance and do a choropleth plot\n",
    "m = folium.Map(location=[53, -2], zoom_start=6)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=post_area,\n",
    "    data=df,\n",
    "    columns=['Postcode_Area','median'],\n",
    "    key_on='feature.properties.name',\n",
    "    bins=8,\n",
    "    fill_color='BuPu',\n",
    "    fill_opacity=.9,\n",
    "    line_opacity=0.5,\n",
    "    nan_fill_opacity=0.\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m.save('map_median1.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = kmeans_geo.loc[kmeans_geo['nGP'] <=4].copy()\n",
    "df = df.groupby('Postcode_Area')['Normalized NIC sum'].agg([np.median,'count'])\n",
    "df = df.loc[df['count'] >15]\n",
    "df['Postcode_Area'] = df.index\n",
    "\n",
    "m = folium.Map(location=[53, -2], zoom_start=6)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=post_area,\n",
    "    data=df,\n",
    "    columns=['Postcode_Area','median'],\n",
    "    key_on='feature.properties.name',\n",
    "    bins=8,\n",
    "    fill_color='BuPu',\n",
    "    fill_opacity=.9,\n",
    "    line_opacity=0.5,\n",
    "    nan_fill_opacity=0.\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m.save('map_median_norm.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = kmeans_geo.loc[kmeans_geo['nGP'] <=4].copy()\n",
    "df = df.groupby('Postcode_Area')['Normalized count'].agg([np.median,'count'])\n",
    "df = df.loc[df['count'] >5]\n",
    "df['Postcode_Area'] = df.index\n",
    "\n",
    "m = folium.Map(location=[53, -2], zoom_start=6)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=post_area,\n",
    "    data=df,\n",
    "    columns=['Postcode_Area','median'],\n",
    "    key_on='feature.properties.name',\n",
    "    bins=8,\n",
    "    fill_color='BuPu',\n",
    "    fill_opacity=.9,\n",
    "    line_opacity=0.5,\n",
    "    nan_fill_opacity=0.\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m.save('map_cnt_norm.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = kmeans_geo.loc[kmeans_geo['nGP'] <=4].copy()\n",
    "df = kmeans_geo.copy()\n",
    "#df = df.loc[df['Normalized NIC sum'] >1e5]\n",
    "#df = df.groupby('Postcode_Area')['Normalized NIC sum'].agg([np.median,'count'])\n",
    "df = df.loc[df['Normalized count']>1200]\n",
    "df = df.groupby('Postcode_Area')['Normalized count'].agg([np.median,'count'])\n",
    "df['Postcode_Area'] = df.index\n",
    "\n",
    "m = folium.Map(location=[53, -2], zoom_start=6)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=post_area,\n",
    "    data=df,\n",
    "    columns=['Postcode_Area','count'],\n",
    "    key_on='feature.properties.name',\n",
    "    bins=8,\n",
    "    fill_color='BuPu',\n",
    "    fill_opacity=.9,\n",
    "    line_opacity=0.5,\n",
    "    nan_fill_opacity=0.\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m.save('map_high_performing.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = kmeans_geo.loc[kmeans_geo['nGP'] <=4].copy()\n",
    "df = kmeans_geo.copy()\n",
    "df = df.loc[df['Normalized NIC sum'] <2e4]\n",
    "df = df.groupby('Postcode_Area')['Normalized NIC sum'].agg([np.median,'count'])\n",
    "df['Postcode_Area'] = df.index\n",
    "\n",
    "m = folium.Map(location=[53, -2], zoom_start=6)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=post_area,\n",
    "    data=df,\n",
    "    columns=['Postcode_Area','count'],\n",
    "    key_on='feature.properties.name',\n",
    "    bins=8,\n",
    "    fill_color='BuPu',\n",
    "    fill_opacity=.9,\n",
    "    line_opacity=0.5,\n",
    "    nan_fill_opacity=0.\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m.save('map_low_performing.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = kmeans_geo.loc[kmeans_geo['nGP'] <=4].copy()\n",
    "df = kmeans_geo.copy()\n",
    "#df = df.loc[df['Normalized NIC sum'] >1e5]\n",
    "#df = df.groupby('Postcode_Area')['Normalized NIC sum'].agg([np.median,'count'])\n",
    "df = df.loc[df['Normalized count']<400]\n",
    "df = df.groupby('Postcode_Area')['Normalized count'].agg([np.median,'count'])\n",
    "df['Postcode_Area'] = df.index\n",
    "\n",
    "m = folium.Map(location=[53, -2], zoom_start=6)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=post_area,\n",
    "    data=df,\n",
    "    columns=['Postcode_Area','count'],\n",
    "    key_on='feature.properties.name',\n",
    "    bins=8,\n",
    "    fill_color='BuPu',\n",
    "    fill_opacity=.9,\n",
    "    line_opacity=0.5,\n",
    "    nan_fill_opacity=0.\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m.save('map_low_performing.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_pop.copy().set_index('Postcode_Area')\n",
    "df['GP_sum'] = filtered_data.join(df_geo.set_index('Practice_Code'))\\\n",
    "                                    .groupby('Postcode_Area').apply(len)\n",
    "df['Postcode_Area'] = df.index\n",
    "df['Popolation_per_Practice'] = df['Population']/df['GP_sum']\n",
    "#df = df.drop(index=['AL'])\n",
    "\n",
    "m = folium.Map(location=[53, -2], zoom_start=6)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=post_area,\n",
    "    name='Pop_per_Practice',\n",
    "    data=df,\n",
    "    columns=['Postcode_Area','Popolation_per_Practice'],\n",
    "    key_on='feature.properties.name',\n",
    "    bins=8,\n",
    "    fill_color='PiYG',\n",
    "    fill_opacity=.9,\n",
    "    line_opacity=0.5,\n",
    "    nan_fill_opacity=0.\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m.save('map_density.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_age.copy().set_index('Postcode_Area')\n",
    "df['senior_frac'] = df['Over 60']/df['All usual residents']\n",
    "#df['GP_sum'] = filtered_data.join(df_geo.set_index('Practice_Code'))\\\n",
    "#                                    .groupby('Postcode_Area').apply(len)\n",
    "df['Postcode_Area'] = df.index\n",
    "#df['Popolation_per_Practice'] = df['Over 60']/df['GP_sum']\n",
    "#df = df.drop(index=['AL'])\n",
    "\n",
    "m = folium.Map(location=[53, -2], zoom_start=6)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=post_area,\n",
    "    name='Pop_per_Practice',\n",
    "    data=df,\n",
    "    columns=['Postcode_Area','senior_frac'],\n",
    "    key_on='feature.properties.name',\n",
    "    bins=8,\n",
    "    fill_color='PiYG',\n",
    "    fill_opacity=.9,\n",
    "    line_opacity=0.5,\n",
    "    nan_fill_opacity=0.\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "#m.save('map_senior_density.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for part 2 starts here.\n",
    "The records are gone through again using Spark, this time looking for pradax prescriptions and its main competitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnflist = ['0208020X0', '0208020Y0', '0208020Z0']\n",
    "grouped = []\n",
    "for n in [201702,201703,201704,201705,201706,201707,201708,201709,201710,201711,201712,201801,201802,201803,201804,201805,201806,201807]:\n",
    "    records = sc.textFile(localpath('data/PDPI/'+str(n)+'/'))\n",
    "    df_rec = records.map(lambda line: line.split(','))\\\n",
    "                    .filter(lambda u: u[1] != 'PCT')\\\n",
    "                    .map(lambda u: (u[2],u[3][:9],int(u[9])))\\\n",
    "                    .filter(lambda v: v[1] in bnflist)\\\n",
    "                    .toDF()\n",
    "    df_rec = df_rec.withColumnRenamed(\"_1\", \"Practice_Code\")\\\n",
    "               .withColumnRenamed(\"_2\", \"BNF\")\\\n",
    "               .withColumnRenamed(\"_3\", \"Date\")\n",
    "    print(df_rec.head())\n",
    "    if grouped == []:\n",
    "        grouped = df_rec\n",
    "    else:\n",
    "        grouped = grouped.union(df_rec)\n",
    "\n",
    "dill.dump(grouped.toPandas(), open('pradax_records.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute #prescription for Pradax and competitors per month for each practice during 201702-201807\n",
    "df_meds = dill.load(open('pradax_records.pkd', 'rb'))\n",
    "\n",
    "dict_meds = {'0208020X0':0, '0208020Y0':1, '0208020Z0':2}\n",
    "dict_labels = {0:'Pradax',1:'Xarelto',2:'Eliquis'}\n",
    "\n",
    "df_meds['Label'] = df_meds['BNF'].apply(lambda u: dict_meds[u])\n",
    "\n",
    "df_meds_cnt = pd.DataFrame()\n",
    "for i in range(3):\n",
    "    df = pd.DataFrame()\n",
    "    df[dict_labels[i]] = df_meds.loc[df_meds['Label']==i].groupby('Practice_Code')['BNF'].count()\n",
    "    if len(df_meds_cnt) == 0:\n",
    "        df_meds_cnt = df\n",
    "    else:\n",
    "        df_meds_cnt = df_meds_cnt.join(df,how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the fraction of Pradax each practice prescribed in 18 months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall fraction\n",
    "fractions = df_meds.groupby('BNF')['Practice_Code'].count().tolist()\n",
    "fractions = np.asarray(fractions)/np.sum(fractions)\n",
    "\n",
    "#Plot into a pie chart\n",
    "fig,ax = plt.subplots(figsize=(6, 3), subplot_kw=dict(aspect=\"equal\"))\n",
    "ax.pie(fractions,explode=[0.1,0.,0.],labels=('Pradax', 'Xarelto', 'Eliquis'),autopct='%1.1f%%',shadow=True)\n",
    "fig.savefig('pie1.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fractions for individual practices\n",
    "df_meds_cnt = df_meds_cnt.fillna(0)\n",
    "df_meds_cnt['Total'] = df_meds_cnt.sum(axis=1)\n",
    "\n",
    "df_meds_frac = pd.DataFrame()\n",
    "df_meds_frac['Fraction'] = df_meds_cnt['Pradax']/df_meds_cnt['Total']\n",
    "df_meds_frac['Total'] = df_meds_cnt['Total']/18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A weighted histogram\n",
    "\n",
    "x = df_meds_frac['Fraction'].tolist()\n",
    "w = df_meds_frac['Total'].tolist()\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.hist(np.asarray(x),bins=np.arange(50)/50.,weights=w)\n",
    "ax.set_xlim((-0.05,0.55))\n",
    "ax.vlines(0.2313,0,5000,linestyles='dashed')\n",
    "#ax.legend()\n",
    "ax.set_xlabel('Fraction of Pradax among competitors \\n (2017/02-2018/07)')\n",
    "ax.set_ylabel('Number of practices')\n",
    "#ax.set_title('Group the data by \\n how many months the practice has on record')\n",
    "fig.tight_layout()\n",
    "fig.savefig('hist2_2.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new visiting scheme and compute #visits per week for each practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meds_frac['weight'] = (1.- df_meds_frac['Fraction'])*df_meds_frac['Total']+2.\n",
    "df_meds_frac['visits_per_week'] = df_meds_frac['weight'] / sum(df_meds_frac['weight']) * len(df_meds_frac) * 0.7\n",
    "df_meds_frac['weeks_per_visit'] = 1./df_meds_frac['visits_per_week']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
